{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583efde6-e3ef-481d-81d2-0ee7c651e9e0",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1e83ab-f3b3-4d39-bdb4-e1019a04c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from operator import itemgetter    \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840988b-27a9-4fba-9eda-0eb6db16d6bb",
   "metadata": {},
   "source": [
    "## Extra Modules to limit Code Clutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60494315-7549-48b5-9489-607c52543da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(folder):\n",
    "    image_list = [] # creating empty list\n",
    "    for file in os.listdir(folder): # iterating through folder\n",
    "        img = cv2.imread(os.path.join(folder, file)) # reading each image in forlder\n",
    "        if img is not None: # only if image read correctly will it be appended\n",
    "            image_list.append(img)\n",
    "    return image_list\n",
    "\n",
    "def convert_image_bw(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img_gray.copy()\n",
    "\n",
    "def show_image_window(img, title):\n",
    "    while True:\n",
    "        cv2.imshow(title, img)\n",
    "        if cv2.waitKey(1) == 27: # if user hits ESC key --> window is exited\n",
    "            break \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def show_image_plt(img, title):\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "\n",
    "def show_row_image_plt(images):\n",
    "    fig = plt.figure()\n",
    "    rows = 1\n",
    "    columns = len(images)\n",
    "    i = 1\n",
    "    for img in images:\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"i\")\n",
    "    \n",
    "def feature_detection(img1, img2):\n",
    "    img1 = convert_image_bw(img1)\n",
    "    img2 = convert_image_bw(img2)\n",
    "    my_SIFT_instance = cv2.SIFT_create()\n",
    "    kp1, desc1 = my_SIFT_instance.detectAndCompute(img1, None) # returns list of keypoints and an array of 128xkp\n",
    "    kp2, desc2 = my_SIFT_instance.detectAndCompute(img2, None) # setting mask field to None\n",
    "    \n",
    "    bf_matcher = cv2.BFMatcher()  # returns the best match\n",
    "    matches = bf_matcher.knnMatch(desc1, desc2, k=2)  # returns the k best matches\n",
    "    good_match = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.6*n.distance: # using each matches euclidean distance\n",
    "            good_match.append(m) \n",
    "    \n",
    "    points_l = np.float32([kp1[i.queryIdx].pt for i in good_match]).reshape(-1, 1, 2) # queryIdx = This attribute gives us the index of the descriptor in the list of img1 descriptors\n",
    "    points_r = np.float32([kp2[i.trainIdx].pt for i in good_match]).reshape(-1, 1, 2) # trainIdx = This attribute gives us the index of the descriptor in the list of img2 descriptors\n",
    "    return points_l, points_r\n",
    "\n",
    "\n",
    "def determine_count(src_img, BM_img): # given keypoints determine if position of BM in L or R\n",
    "    count = 0\n",
    "    for i in range(len(src_img)):\n",
    "        if BM_img[i][0][0] < src_img[i][0][0]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def remove_element(my_list, target):\n",
    "    my_list.remove(target)\n",
    "    return my_list\n",
    "\n",
    "def remove_border_list(list_of_img):\n",
    "    list_copy = list_of_img.copy()\n",
    "    for i in range(len(list_copy)):\n",
    "        bw = cv2.cvtColor(list_copy[i],cv2.COLOR_BGR2GRAY)\n",
    "        _,threshold = cv2.threshold(bw,0,255,cv2.THRESH_BINARY)\n",
    "        contours,_ = cv2.findContours(threshold,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        x,y,w,h = cv2.boundingRect(contours[0])\n",
    "        list_copy[i] = list_copy[i][y:y+h,x:x+w]\n",
    "    return list_copy\n",
    "\n",
    "def remove_border(img):\n",
    "    img_copy = img.copy()\n",
    "    bw = cv2.cvtColor(img_copy,cv2.COLOR_BGR2GRAY)\n",
    "    _,threshold = cv2.threshold(bw,0,255,cv2.THRESH_BINARY)\n",
    "    contours,_ = cv2.findContours(threshold,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    x,y,w,h = cv2.boundingRect(contours[0])\n",
    "    img_copy = img_copy[y:y+h,x:x+w]\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031a71a-3522-4c9b-97ce-dbd3a69f901f",
   "metadata": {},
   "source": [
    "## STEP 01 MATCH FEATURES: Feature Extraction and Feature Correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0878c778-58bd-4e3c-ac2a-d75da02f47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features(folder): # STEP 01: The first step is to extract features from the images, and automatically establish feature correspondences between image pairs.\n",
    "    start_time = time.time()\n",
    "    sorted_image_list = []\n",
    "    images_to_compare = [i for i in range(len(folder))] # initialize list of images to compare w current\n",
    "    current_image = 0\n",
    "    sorted_image_list.append(current_image) # add the first image to the list\n",
    "    images_to_compare = remove_element(images_to_compare, current_image) # remove it from the compare list and find the closest R image\n",
    "    count_list = []\n",
    "    while True:\n",
    "        # print(\"Images Left To Compare: {}\".format(images_to_compare))\n",
    "        max_count = 0\n",
    "        best_match = 0\n",
    "        if len(images_to_compare) == 1: # check if last image in list is to the L of initial image\n",
    "            pi, pj = feature_detection(folder[images_to_compare[0]], folder[sorted_image_list[0]])\n",
    "            count = determine_count(pi, pj)\n",
    "            pi2, pj2 = feature_detection(folder[sorted_image_list[0]], folder[sorted_image_list[1]])\n",
    "            count2 = determine_count(pi2, pj2)\n",
    "            if count >= count2*0.6:\n",
    "                sorted_image_list.insert(0, images_to_compare[0])\n",
    "            images_to_compare = remove_element(images_to_compare, images_to_compare[0])\n",
    "        if len(images_to_compare) == 0:\n",
    "            print(\"Sorted Order: {}\".format(sorted_image_list))\n",
    "            break\n",
    "        for j in images_to_compare:\n",
    "            # print(\"COMPARING WITH: \", j)\n",
    "            pi, pj = feature_detection(folder[current_image], folder[j])\n",
    "            count = determine_count(pi, pj)\n",
    "            if count > max_count:\n",
    "                max_count = count\n",
    "                best_match = j\n",
    "                # print(\"BM UPDATED\")\n",
    "        sorted_image_list.append(best_match)\n",
    "        print(\"Sorted Order: {}\".format(sorted_image_list))\n",
    "        images_to_compare = remove_element(images_to_compare, best_match)\n",
    "        current_image = best_match\n",
    "        count_list.append(max_count)\n",
    "        print(\"MATCH METRIC OUTPUT: {}\".format(count_list))\n",
    "    print(\"--- MATCH FEATURES EXECUTION TIME: %s seconds ---\" % (time.time() - start_time))\n",
    "    return sorted_image_list\n",
    "\n",
    "def determine_image_pairs(sorted_list, folder):\n",
    "    start_time = time.time()\n",
    "    center_img = int(len(sorted_list)/2)\n",
    "    leftward_pairs = []\n",
    "    rightward_pairs = []\n",
    "    for i in range(len(sorted_list)): # want to warp <-<-<-<-=->->->->\n",
    "        if i < center_img:\n",
    "            current_index = i \n",
    "            warp_onto = i+1\n",
    "            leftward_pairs.append((sorted_list[current_index], sorted_list[warp_onto]))\n",
    "        if i > center_img and i < len(sorted_list)-1:\n",
    "            current_index = i\n",
    "            warp_onto = i+1\n",
    "            rightward_pairs.append((sorted_list[current_index], sorted_list[warp_onto]))\n",
    "    print(\"--- DETERMINING IMAGE PAIRS TIME: %s seconds ---\" % (time.time() - start_time))\n",
    "    return leftward_pairs, rightward_pairs, center_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d86490-5339-4b8f-9f40-5f40bbaa9e70",
   "metadata": {},
   "source": [
    "## STEP02 ESTIMATE TRANSFORMATION: Calculating Transformations Between Matched Features\n",
    "## STEP 03 MERGE IMAGES: Applying Geometric and Radiometric Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9b88f9-d99b-4dd2-be38-4c1ac28b17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inital_pair_warp_R(rightward_pairs, folder):\n",
    "    warped_img = []\n",
    "    list_of_pair_warps = []\n",
    "    list_of_warps = []\n",
    "    for i in range(len(rightward_pairs)): # from center->0\n",
    "        print(\"Pair: {}\".format(i))\n",
    "        right_img = folder[rightward_pairs[i][1]]\n",
    "        left_img = folder[rightward_pairs[i][0]]\n",
    "        pi, pj = feature_detection(right_img, left_img) # project left image onto image to right\n",
    "        M, _ = cv2.findHomography(pi, pj, cv2.RANSAC, 5.0)\n",
    "        h1, w1, _1 = right_img.shape\n",
    "        h2, w2, _2 = left_img.shape\n",
    "        width = w1+w2\n",
    "        height = h2+h1\n",
    "        warped_img = cv2.warpPerspective(right_img, M, (width, height))\n",
    "        warped_img[0:h2, 0:w2] = left_img\n",
    "        list_of_warps.append(warped_img)\n",
    "    print(len(list_of_warps))\n",
    "    list_of_pair_warps = remove_border_list(list_of_warps)\n",
    "    return list_of_pair_warps\n",
    "\n",
    "def warping_to_right_pair(right_img, left_img):\n",
    "    warped_img = []\n",
    "    pi, pj = feature_detection(right_img, left_img) # project left image onto image to right\n",
    "    M, _ = cv2.findHomography(pi, pj, cv2.RANSAC, 5.0)\n",
    "    h1, w1, _1 = right_img.shape\n",
    "    h2, w2, _2 = left_img.shape\n",
    "    width = w1+w2\n",
    "    height = h2+h1\n",
    "    warped_img = cv2.warpPerspective(right_img, M, (width, height))\n",
    "    warped_img[0:h2, 0:w2] = left_img\n",
    "    warped_img = remove_border(warped_img)\n",
    "    return warped_img\n",
    "\n",
    "def recursive_warping_R(rightward_pairs, folder):\n",
    "    r_copy = rightward_pairs.copy()\n",
    "    input_list = []\n",
    "    output_list = inital_pair_warp_R(r_copy, folder)\n",
    "    final_warp = []\n",
    "    while True:\n",
    "        if len(output_list) == 1: # if the final output is only one image of all combined images we are done\n",
    "            break\n",
    "        print(\"OUTPUT LEN:{}\".format(len(output_list)))\n",
    "        input_list = output_list.copy()\n",
    "        output_list.clear()\n",
    "        while True:\n",
    "            print(\"INPUT LEN:{}\".format(len(input_list))) \n",
    "            if len(input_list) == 1: # if size is odd just add last image to end\n",
    "                print(\"List Is ODD\")\n",
    "                output_list.append(input_list[0])\n",
    "                input_list.clear()\n",
    "            if len(input_list) == 0:\n",
    "                break\n",
    "            warped_img = []\n",
    "            right_img = input_list[1]\n",
    "            left_img = input_list[0]\n",
    "            input_list.remove(left_img)\n",
    "            input_list.remove(right_img)\n",
    "            warped_img = warping_to_right_pair(right_img, left_img) \n",
    "            output_list.append(warped_img)\n",
    "    print(\"DONE\")\n",
    "    final_warp = output_list[0]\n",
    "    return final_warp\n",
    "# -----------------------------------------------------------------------\n",
    "# Flipping all LEFTWARD_PAIR IMAGES TO APPLY RIGHTWARD STITCHING AND FLIPPING RESULT\n",
    "def flip_image2(img):\n",
    "    print(\"Flipping\")\n",
    "    img_height, img_width, img_channel = img.shape\n",
    "    hor_flipped_img = np.zeros((img_height,img_width,3), np.uint8) # initializing empty images with same width, height, channel and dtype\n",
    "    for i in range(img_height):\n",
    "        for j in range(img_width):\n",
    "            for k in range(img_channel):\n",
    "                hor_flipped_img[i][j][k] = img[i][img_width-j-1][k] # horizontally flipped image has a reveresed order of columns in its array values\n",
    "    return hor_flipped_img\n",
    "\n",
    "def flip_image(img):\n",
    "    img = cv2.flip(img, 1)\n",
    "    return img\n",
    "\n",
    "# Apply initial warps from leftward_pairs list and flip all images and send to recursive warp\n",
    "def inital_pair_warp_L(leftward_pairs, folder):\n",
    "    warped_img = []\n",
    "    list_of_pair_warps = []\n",
    "    list_of_warps = []\n",
    "    for i in range(len(leftward_pairs)): # from center->0\n",
    "        print(\"RIGHT: {}, LEFT: {}\".format(leftward_pairs[i][1], leftward_pairs[i][0]))\n",
    "        right_img = flip_image(folder[leftward_pairs[i][0]])\n",
    "        left_img = flip_image(folder[leftward_pairs[i][1]])\n",
    "        print(\"flipped\")\n",
    "        pi, pj = feature_detection(right_img, left_img) # project right image onto image to left\n",
    "        M, _ = cv2.findHomography(pi, pj, cv2.RANSAC, 5.0)\n",
    "        h1, w1, _1 = right_img.shape\n",
    "        h2, w2, _2 = left_img.shape\n",
    "        width = w1+w2\n",
    "        height = h2+h1\n",
    "        warped_img = cv2.warpPerspective(right_img, M, (width, height)) # warp R IMG IN TERMS OF L IMG\n",
    "        warped_img[0:h2, 0:w2] = left_img # left image is maintained at beginning of image, warped R_img is \"added\" to end \n",
    "        list_of_warps.append(warped_img)\n",
    "        print(len(list_of_warps))\n",
    "    list_of_pair_warps = remove_border_list(list_of_warps) # remove border around images\n",
    "    initial_pair_list = list_of_pair_warps.copy()\n",
    "    return initial_pair_list\n",
    "\n",
    "def recursive_warping_L(leftward_pairs, folder):\n",
    "    l_copy = leftward_pairs.copy()\n",
    "    input_list = []\n",
    "    output_list = inital_pair_warp_L(l_copy , folder) # warping all the inital pairs together -> convert pair list to images\n",
    "    final_warp = []\n",
    "    while True:\n",
    "        if len(output_list) == 1: # if the final output is only one image of all combined images we are done\n",
    "            break\n",
    "        else:\n",
    "            print(\"OUTPUT LEN:{}\".format(len(output_list)))\n",
    "            input_list = output_list.copy()\n",
    "            output_list.clear()\n",
    "            while True:\n",
    "                print(\"INPUT LEN:{}\".format(len(input_list))) \n",
    "                if len(input_list) == 1: # if size is odd just add last image to end\n",
    "                    print(\"List Is ODD\")\n",
    "                    output_list.append(input_list[0])\n",
    "                    input_list.clear()\n",
    "                if len(input_list) == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    warped_img = []\n",
    "                    right_img = input_list[1]\n",
    "                    left_img = input_list[0]\n",
    "                    input_list.remove(left_img)\n",
    "                    input_list.remove(right_img)\n",
    "                    warped_img = warping_to_right_pair(right_img, left_img) \n",
    "                    output_list.append(warped_img)\n",
    "        plt.imshow(warped_img)\n",
    "        plt.show()\n",
    "    print(\"DONE\")\n",
    "    final_warp = flip_image(output_list[0])\n",
    "    return final_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57fbbf47-ccda-400e-9a12-77507759d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Folder\n",
    "def AutoStitch_Panorama(folder_name):\n",
    "    start_time = time.time()\n",
    "    folder_images = load_folder(folder_name)\n",
    "    img_list = match_features(folder_images)\n",
    "    leftward_pairs, rightward_pairs, center_img = determine_image_pairs(img_list, folder_images)\n",
    "    R_final = recursive_warping_R(rightward_pairs, folder_images)\n",
    "    L_final = recursive_warping_L(leftward_pairs, folder_images)\n",
    "    FINAL_PANO = warping_to_right_pair(R_final, L_final)\n",
    "    print(\"--- FULL AUTOSTITCH EXECUTION TIME: %s seconds ---\" % (time.time() - start_time))\n",
    "    return FINAL_PANO, R_final, L_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0abd4698-4a3d-474f-b6f1-c28880d3e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Order: [0, 1]\n",
      "MATCH METRIC OUTPUT: [542]\n",
      "Sorted Order: [0, 1, 2]\n",
      "MATCH METRIC OUTPUT: [542, 467]\n",
      "Sorted Order: [0, 1, 2, 3]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390]\n",
      "Sorted Order: [0, 1, 2, 3, 4]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558, 835]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558, 835, 523]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558, 835, 523, 316]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558, 835, 523, 316, 390]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558, 835, 523, 316, 390, 466]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558, 835, 523, 316, 390, 466, 323]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558, 835, 523, 316, 390, 466, 323, 177]\n",
      "Sorted Order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "MATCH METRIC OUTPUT: [542, 467, 390, 121, 173, 146, 139, 159, 166, 350, 273, 356, 553, 460, 555, 675, 702, 724, 558, 835, 523, 316, 390, 466, 323, 177, 364]\n",
      "Sorted Order: [28, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "--- MATCH FEATURES EXECUTION TIME: 1379.1784977912903 seconds ---\n",
      "--- DETERMINING IMAGE PAIRS TIME: 0.0 seconds ---\n",
      "Pair: 0\n",
      "Pair: 1\n",
      "Pair: 2\n",
      "Pair: 3\n",
      "Pair: 4\n",
      "Pair: 5\n",
      "Pair: 6\n",
      "Pair: 7\n",
      "Pair: 8\n",
      "Pair: 9\n",
      "Pair: 10\n",
      "Pair: 11\n",
      "Pair: 12\n",
      "13\n",
      "OUTPUT LEN:13\n",
      "INPUT LEN:13\n",
      "INPUT LEN:11\n",
      "INPUT LEN:9\n",
      "INPUT LEN:7\n",
      "INPUT LEN:5\n",
      "INPUT LEN:3\n",
      "INPUT LEN:1\n",
      "List Is ODD\n",
      "OUTPUT LEN:7\n",
      "INPUT LEN:7\n",
      "INPUT LEN:5\n",
      "INPUT LEN:3\n",
      "INPUT LEN:1\n",
      "List Is ODD\n",
      "OUTPUT LEN:4\n",
      "INPUT LEN:4\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\fundam.cpp:385: error: (-28:Unknown error code -28) The input arrays should have at least 4 corresponding point sets to calculate Homography in function 'cv::findHomography'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f0dee6787f70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoStitch_Panorama\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'office2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-55e4998f9af2>\u001b[0m in \u001b[0;36mAutoStitch_Panorama\u001b[1;34m(folder_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mleftward_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightward_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetermine_image_pairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mR_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecursive_warping_R\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrightward_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mL_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecursive_warping_L\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleftward_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mFINAL_PANO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwarping_to_right_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-eaeace2c6c27>\u001b[0m in \u001b[0;36mrecursive_warping_R\u001b[1;34m(rightward_pairs, folder)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0minput_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0minput_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mwarped_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwarping_to_right_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0moutput_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarped_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DONE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-eaeace2c6c27>\u001b[0m in \u001b[0;36mwarping_to_right_pair\u001b[1;34m(right_img, left_img)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mwarped_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_img\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# project left image onto image to right\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindHomography\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRANSAC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mh1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mright_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mh2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\fundam.cpp:385: error: (-28:Unknown error code -28) The input arrays should have at least 4 corresponding point sets to calculate Homography in function 'cv::findHomography'\n"
     ]
    }
   ],
   "source": [
    "img_1, R_final, L_final = AutoStitch_Panorama('office2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e552f671-9acc-4ea2-8d49-85a411e0d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('Resulting_Composite_Img_01.jpg', img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f357d9-387c-4c32-8797-c39e22495cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('Resulting_Left_Pano_01.jpg', L_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f4c15-fb15-4515-9ac6-a5669506d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('Resulting_Right_Pano_01.jpg', R_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d06cfc-b949-4548-88d0-aa6084f0303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2, R_final2, L_final2 = AutoStitch_Panorama('StJames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdb97a-4f28-4dc6-af6e-4dd23477e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('Resulting_Composite_Img_02.jpg', img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d5c86-749d-437a-80ee-b28807394db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_3, R_final3, L_final3 = AutoStitch_Panorama('WLH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d435d7d-e615-43c3-a227-ba3a90c742d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('Resulting_Composite_Img_03.jpg', img_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
